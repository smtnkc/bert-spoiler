{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "occupational-illness",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "pd.options.display.float_format = '{:,}'.format\n",
    "random.seed(2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "utility-remove",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(file_name):\n",
    "    classes = []\n",
    "    texts = []\n",
    "    n_review = 0\n",
    "    print('current line: ', end='')\n",
    "    with gzip.open(file_name) as fin:\n",
    "        for l in fin:\n",
    "            d = json.loads(l)\n",
    "            if n_review % 1000000 == 0:\n",
    "                print(n_review, end=',')\n",
    "            n_review += 1\n",
    "            for label, sentence in d['review_sentences']:\n",
    "                #//n_sentence += 1\n",
    "                #n_spoiler_sentence += _t\n",
    "                classes.append(label)\n",
    "                texts.append(sentence)\n",
    "            #n_spoiler_review += int(d['has_spoiler'])\n",
    "            #book_set.add(d['book_id'])\n",
    "            #user_set.add(d['user_id'])\n",
    "    print('complete')\n",
    "    print('done!')\n",
    "    df = pd.DataFrame({'class' : classes, 'text' : texts})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "desperate-estimate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current line: 0,1000000,complete\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "df = load_dataset('goodreads_reviews_spoiler.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "consistent-economy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>This is a special book.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>It started slow for about the first third, the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>This is what I love about good science fiction...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>It is a 2015 Hugo winner, and translated from ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>For instance the intermixing of Chinese revolu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class                                               text\n",
       "0      0                            This is a special book.\n",
       "1      0  It started slow for about the first third, the...\n",
       "2      0  This is what I love about good science fiction...\n",
       "3      0  It is a 2015 Hugo winner, and translated from ...\n",
       "4      0  For instance the intermixing of Chinese revolu..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "pressed-computer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17672655"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "needed-upgrade",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('csv_datasets/goodreads/goodreads_all.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "binding-norwegian",
   "metadata": {},
   "source": [
    "# Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "hourly-parcel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nonspoiler: 17102931\n",
      "spoiler: 569724\n",
      "weight-decreased nonspoiler: 855147\n",
      "balanced total: 1424871\n"
     ]
    }
   ],
   "source": [
    "df_non = df[df['class'] == 0]\n",
    "df_spoiler = df[df['class'] == 1]\n",
    "print(\"nonspoiler:\", len(df_non))\n",
    "print(\"spoiler:\", len(df_spoiler))\n",
    "df_non = df_non.sample(frac =.05)\n",
    "print(\"weight-decreased nonspoiler:\", len(df_non))\n",
    "print(\"balanced total:\", len(df_non)+len(df_spoiler))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupied-indication",
   "metadata": {},
   "source": [
    "# train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "backed-livestock",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 70/10/20 train/val/test\n",
    "df_train_non = df_non.sample(frac = .70)\n",
    "df_non = df_non.drop(df_train_non.index)\n",
    "df_train_spoiler = df_spoiler.sample(frac = .70)\n",
    "df_spoiler = df_spoiler.drop(df_train_spoiler.index)\n",
    "\n",
    "# use 33% of the remaining for validation (which is 10% of whole dataset)\n",
    "df_dev_non = df_non.sample(frac = .333)\n",
    "df_non = df_non.drop(df_dev_non.index)\n",
    "df_dev_spoiler = df_spoiler.sample(frac = .333)\n",
    "df_spoiler = df_spoiler.drop(df_dev_spoiler.index)\n",
    "\n",
    "# use all of the remaining for test (which is 20% of whole dataset)\n",
    "df_test_non = df_non\n",
    "df_test_spoiler = df_spoiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "worldwide-understanding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 997410\n",
      "dev: 142344\n",
      "test: 285117\n",
      "all: 1424871\n"
     ]
    }
   ],
   "source": [
    "# merge and shuffle\n",
    "\n",
    "df_train = pd.concat([df_train_non, df_train_spoiler])\n",
    "df_train = df_train.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "df_dev = pd.concat([df_dev_non, df_dev_spoiler])\n",
    "df_dev = df_dev.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "df_test = pd.concat([df_test_non, df_test_spoiler])\n",
    "df_test = df_test.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "print(\"train:\",len(df_train))\n",
    "print(\"dev:\",len(df_dev))\n",
    "print(\"test:\",len(df_test))\n",
    "print(\"all:\",len(df_train)+len(df_dev)+len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "agreed-remove",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('csv_datasets/goodreads/train.csv', index=False)\n",
    "df_dev.to_csv('csv_datasets/goodreads/dev.csv', index=False)\n",
    "df_test.to_csv('csv_datasets/goodreads/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specific-stanford",
   "metadata": {},
   "source": [
    "# sample to try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "pharmaceutical-gabriel",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_sample = df_train.sample(7000)\n",
    "df_dev_sample = df_dev.sample(1000)\n",
    "df_test_sample = df_test.sample(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "buried-consumer",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train_sample.to_csv('csv_datasets/goodreads/sample/train.csv', index=False)\n",
    "df_dev_sample.to_csv('csv_datasets/goodreads/sample/dev.csv', index=False)\n",
    "df_test_sample.to_csv('csv_datasets/goodreads/sample/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollywood-lover",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
